<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>The blog of Linyao Li</title>
 <link href="http://example.com/atom.xml" rel="self"/>
 <link href="http://example.com"/>
 <updated>2017-04-06T23:09:52-07:00</updated>
 <id>http://example.com</id>
 <author>
   <name>Linyao Li</name>
   <email></email>
 </author>

 
 <entry>
   <title>Scalability Rules</title>
   <link href="http://example.com/2017/04/06/scalability-rules.html"/>
   <updated>2017-04-06T00:00:00-07:00</updated>
   <id>http://example.com/2017/04/06/scalability-rules</id>
   <content type="html">&lt;p&gt;This post is a note/headline for reading book Scalability Rules, so in the future I can look back
to this rather than finding the book. If you find this interesting, go search &lt;a href=&quot;https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=scalability+rules&quot;&gt;Scalability Rules&lt;/a&gt;. Great book.&lt;/p&gt;

&lt;p&gt;Before all of these below, please devote to the bible of scalable system &lt;a href=&quot;https://en.wikipedia.org/wiki/CAP_theorem&quot;&gt;CAP&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#i-reduce-the-equation&quot; id=&quot;markdown-toc-i-reduce-the-equation&quot;&gt;I. Reduce the equation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ii-distribute-the-work&quot; id=&quot;markdown-toc-ii-distribute-the-work&quot;&gt;II. Distribute the work&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#iii-design-to-scale-out-horizontally&quot; id=&quot;markdown-toc-iii-design-to-scale-out-horizontally&quot;&gt;III. Design to scale out horizontally&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#iv-use-the-right-tools&quot; id=&quot;markdown-toc-iv-use-the-right-tools&quot;&gt;IV. Use the right tools&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#v-dont-duplicate-your-work&quot; id=&quot;markdown-toc-v-dont-duplicate-your-work&quot;&gt;V. Don’t duplicate your work&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#vi-use-caching-aggressively-damn-i-love-it&quot; id=&quot;markdown-toc-vi-use-caching-aggressively-damn-i-love-it&quot;&gt;VI. Use caching aggressively. Damn I love it.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;i-reduce-the-equation&quot;&gt;I. Reduce the equation&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Don’t overengineer the solution. Complex systems result in costly effort and maintaince, decompose complex requiments into smaller systems, and make them sharable and reusable.&lt;/li&gt;
  &lt;li&gt;Design scale into solution. Design to 20x capacity, implemenet for 3x capacity, deploy for ~1.5x capacity.&lt;/li&gt;
  &lt;li&gt;Simply the solution 3 times over(Pareto Principle). This falls into the Rule(1), but remember simplification is not necessarily considered as always good.&lt;/li&gt;
  &lt;li&gt;Reduce DNS lookups.&lt;/li&gt;
  &lt;li&gt;Reduce objects where possible. Frontend stuffs.&lt;/li&gt;
  &lt;li&gt;Use homogenous networks. Hardware.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ii-distribute-the-work&quot;&gt;II. Distribute the work&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://ranjithabalaraman.files.wordpress.com/2014/10/scaledb.png&quot; alt=&quot;three axes of scale&quot; /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Design to clone things(x-axis). Or horizontal scalability, essentially the duplication of services. This is the most important ideology in scalability I’d say.
    &lt;ul&gt;
      &lt;li&gt;For services, ensure it is logically simple(use standardized interface e.g. RESTful/RPC) and easy to clone, use load balancer.&lt;/li&gt;
      &lt;li&gt;For databases, normally used when Read » Write. Master-Slave / Consistent Hashing etc. note &lt;a href=&quot;https://en.wikipedia.org/wiki/ACID&quot;&gt;ACID&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Design to split different things(y-axis). Which I don’t care much.&lt;/li&gt;
  &lt;li&gt;Design to split similar things(z-axis). ..Either.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;iii-design-to-scale-out-horizontally&quot;&gt;III. Design to scale out horizontally&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Design your solution to scale out, not just up.
    &lt;ul&gt;
      &lt;li&gt;Scaling out means the replication of services.&lt;/li&gt;
      &lt;li&gt;Scaling up means upgrade of computing resources.
  This is really just a duplicate from Rule(7). meh.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use commodiity systems. Be cost-effective.&lt;/li&gt;
  &lt;li&gt;Scale out your data centers. This is more of a concern on availability and failover, so always prepare for multiple data centers. Models may vary.&lt;/li&gt;
  &lt;li&gt;Design to leverage the cloud. e.g store unimportant files in S3 (I will never save important data in S3).&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;iv-use-the-right-tools&quot;&gt;IV. Use the right tools&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Use databases appropriately.
    &lt;ul&gt;
      &lt;li&gt;Use RDBMS for cross-table lookup. e.g. MySQL.&lt;/li&gt;
      &lt;li&gt;Use NoSQL for simple R/W key-value queries. e.g. for great scalability, Cassandra; for grete &lt;a href=&quot;https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type&quot;&gt;CRDT&lt;/a&gt; support, Riak; for light weight, LevelDB. There are tons of options, the world of database is heaven.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Don’t abusively use firewalls, it makes network slow. Put firewall only in critical path.&lt;/li&gt;
  &lt;li&gt;It is never too less for logging. Use reliable and fast tool such as &lt;a href=&quot;https://github.com/zendesk/maxwell&quot;&gt;Maxwell&lt;/a&gt; for aggregation, and make it well rotated.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;v-dont-duplicate-your-work&quot;&gt;V. Don’t duplicate your work&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Don’t check your work. I’d say avoid duplicated data validation, act upon failures.&lt;/li&gt;
  &lt;li&gt;Reduce redirecting traffic. This only applies for HTML level, per se. Traffic redirection is key in server configuration and load balancing, especially for inter-service traffic.&lt;/li&gt;
  &lt;li&gt;Alleviate temporal constraints.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;vi-use-caching-aggressively-damn-i-love-it&quot;&gt;VI. Use caching aggressively. Damn I love it.&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Leverage CDN.&lt;/li&gt;
  &lt;li&gt;Use &lt;code&gt;Expires&lt;/code&gt; headers. HTML &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_HTTP_header_fields&quot;&gt;headers&lt;/a&gt; offer more than you could ever imagine.&lt;/li&gt;
  &lt;li&gt;Cache Ajax calls. Use &lt;code&gt;Last-Modified&lt;/code&gt;, &lt;code&gt;Cache-Control&lt;/code&gt; and &lt;code&gt;Expires&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Leverage page caches. &lt;a href=&quot;https://www.nginx.com/resources/glossary/reverse-proxy-server/&quot;&gt;Reverse proxy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Utilize application caches. Cache whatever users mostly request, find the best balance between performance and cost.&lt;/li&gt;
  &lt;li&gt;Make use of object caches(aka in-memory cache).&lt;/li&gt;
  &lt;li&gt;Put object caches on their own tier. Though I regretly did this mutiple times, caching should never be embedded with crtical path. i.e. whenever caching fails, request should always be properly forwarded to database. Generally, a caching service should sit between api layer and service layer(which operates database commands).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;NEXT: Learn from mistakes&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>mocha test exceeds timeout</title>
   <link href="http://example.com/2017/03/23/mocha-timeout.html"/>
   <updated>2017-03-23T00:00:00-07:00</updated>
   <id>http://example.com/2017/03/23/mocha-timeout</id>
   <content type="html">&lt;p&gt;For the following case, you may see macha test exceeds timeout even with &lt;code&gt;timeout(6000)&lt;/code&gt; setup.
Be sure to resolve promise at the end setTimeout.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;it('blah', () =&amp;gt; ) {
  this.timeout(6000)
  return new Promise((resolve) =&amp;gt; {
    setTimeout(() =&amp;gt; {
      helper.request().get('/testurl/' + id)
      .then()//whatever
    resolve() &amp;lt;=== don't forget this!
    }, 5000)
  })
}
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>nginx's add_header is not working</title>
   <link href="http://example.com/2017/02/23/nginx-add-header.html"/>
   <updated>2017-02-23T00:00:00-08:00</updated>
   <id>http://example.com/2017/02/23/nginx-add-header</id>
   <content type="html">&lt;p&gt;Just in case anyone turns into a clusterfuck that:
NO, stackoverflow doesn’t help!(just like me)
try this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;set $content_disposition $upstream_http_content_disposition;
...
add_header Content-Disposition $content_disposition;
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>A Typical Design of Database Backfill System</title>
   <link href="http://example.com/2016/03/07/backfill-systems.html"/>
   <updated>2016-03-07T00:00:00-08:00</updated>
   <id>http://example.com/2016/03/07/backfill-systems</id>
   <content type="html">&lt;p&gt;status: WIP&lt;/p&gt;

&lt;p&gt;At some point, we may need to backfill new columns in a frequently queried table. Assume there are massive amount of
records, and each record has blah blah..&lt;/p&gt;

&lt;hr /&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#generate-backfill-audits&quot; id=&quot;markdown-toc-generate-backfill-audits&quot;&gt;Generate backfill audits&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#daemon-to-run-backfill-tasks&quot; id=&quot;markdown-toc-daemon-to-run-backfill-tasks&quot;&gt;Daemon to run backfill tasks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#a-general-task&quot; id=&quot;markdown-toc-a-general-task&quot;&gt;A General Task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#task-list&quot; id=&quot;markdown-toc-task-list&quot;&gt;Task list&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#a-sample-backfill-task&quot; id=&quot;markdown-toc-a-sample-backfill-task&quot;&gt;A sample backfill task&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;generate-backfill-audits&quot;&gt;Generate backfill audits&lt;/h2&gt;
&lt;p&gt;To maintain durable backfill tasks in the rails application, especially while
backfilling huge loads of records, we’d like to make these audits trackable, and
work on them in a specific order.&lt;/p&gt;

&lt;p&gt;For that, we need a table as the following:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;backfill_audits&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;id&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;account_id&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;task&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;created_at&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;started_at&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;completed_at&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;updated_at&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The only notable thing here is, on an extreme case when we are backfilling shits during a migration, new record can be
inserted, therefore a re-backfill is needed. For this situation, we put a waterline inside the audits marking a period
to avoid a whole table re-backfilling.&lt;/p&gt;

&lt;p&gt;Since this case does not happen constantly, one day gap is good enough (or extend to even longer depending on the amount of records).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;module DurableBackfill
  class BackfillAudit &amp;lt; ActiveRecord::Base
    WATERLINE_ACCOUNT_ID = -10

    default_scope { where(&quot;account_id != #{WATERLINE_ACCOUNT_ID}&quot;) }

    scope :for_task, -&amp;gt;(task_name) { where(task: task_name) }
    scope :incomplete, -&amp;gt; { where(completed_at: nil) }

    belongs_to :account

    def self.waterline_date(task)
      unscoped.where(account_id: WATERLINE_ACCOUNT_ID, task: task).first_or_create.created_at + 1.day
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;daemon-to-run-backfill-tasks&quot;&gt;Daemon to run backfill tasks&lt;/h2&gt;

&lt;p&gt;Before starting the actual backfill task, let’s create backfill audits.
Unless we have fully backfilled the table, backfill task need to run continuously in the background.
Three minutes is not necessarily a good gap, but it is always open to change based on actual circumstances.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;require_relative 'task_list'

module DurableBackfill
  class Runner
    def self.tasks
      DurableBackfill::Task.descendants
    end

    def run
      generate_backfills
      while true do
        work_backfills
        sleep(3.minutes)
      end
    end

    def generate_backfills
      tasks.each do |task|
        ActiveRecord::Base.on_all_shards do |shard_id|
          task.create_audits!
        end
      end
    end

    def work_backfills
      tasks.each do |task|
        ActiveRecord::Base.on_all_shards do |shard_id|
          task.audits.incomplete.find_each do |audit|
            task.new(audit).work_audit
          end
        end
      end
    end

    private

    def tasks
      self.class.tasks
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;a-general-task&quot;&gt;A General Task&lt;/h2&gt;

&lt;p&gt;A waterline account is not a real account, therefore do be aware that its id must not conflict with real account ids.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;module DurableBackfill
  class Task
    class RescheduleTask &amp;lt; StandardError ; end
    WATERLINE_ACCOUNT_ID = -10

    class &amp;lt;&amp;lt; self
      attr_accessor :title

      def audits
        DurableBackfill::BackfillAudit.for_task(title)
      end

      def create_audits!
        waterline = DurableBackfill::BackfillAudit.waterline_date(title)

        DurableBackfill::BackfillAudit.transaction do
          created_accounts = DurableBackfill::BackfillAudit.for_task(title).pluck(:account_id).to_set

          Account.shard_local.where(&quot;created_at &amp;lt; ?&quot;, waterline).where(&quot;id != #{Account.system_account_id}&quot;).each do |account|
            next if created_accounts.include?(account.id)

            DurableBackfill::BackfillAudit.create!(task: title, account: account)
          end
        end
      end
    end

    def initialize(audit)
      @audit = audit
    end

    def work(account)
      raise &quot;must implement work!&quot;
    end

    def work_audit
      @audit.started_at = Time.now
      if @audit.account(true).shard_local?
        puts &quot;work on account#{@audit.account.id}&quot;
        work(@audit.account)
      end

      @audit.completed_at = Time.now
      @audit.save!
    rescue RescheduleTask =&amp;gt; e
      # leave audit untouched
    end

    def reschedule!
      raise RescheduleTask.new
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;task-list&quot;&gt;Task list&lt;/h2&gt;

&lt;p&gt;We use a tasks folder to keep all actual tasks.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;files = Dir.glob(File.dirname(__FILE__) + &quot;/tasks/*.rb&quot;).each do  |f|
  require f
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;a-sample-backfill-task&quot;&gt;A sample backfill task&lt;/h2&gt;

&lt;p&gt;Now I’d like to backfill the column number_of_employee in table &lt;code&gt;company&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;module DurableBackfill
  class BackfillNumberOfEmployee &amp;lt; Task
    self.title = 'backfill_number_of_employee'

    def work(account)
      Rails.cache.write(&quot;durable-backfill-number-of-employee-#{account.id}&quot;, true)

      Company.where(:account_id =&amp;gt; account.id).find_each do |t|
        t.update_attribute(:number_of_employee, t.count_employee)
      end
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 
</feed>
